"""
APScheduler ê¸°ë°˜ ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ ì„œë¹„ìŠ¤

ì„œë²„ ìƒíƒœ ìë™ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ìŠ¤ì¼€ì¤„ëŸ¬ ê´€ë¦¬
"""

import logging
import asyncio
from datetime import datetime, timedelta
from typing import Optional, Dict, List

from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.interval import IntervalTrigger
from apscheduler.executors.asyncio import AsyncIOExecutor
from apscheduler.jobstores.memory import MemoryJobStore
from apscheduler import events
from sqlalchemy.orm import Session

from ..database import get_db
from ..models import McpServer, Project, WorkerConfig
from ..models.mcp_server import McpTool, McpServerStatus
from ..services.mcp_connection_service import mcp_connection_service
from ..services.server_status_service import ServerStatusService

logger = logging.getLogger(__name__)


class SchedulerService:
    """APScheduler ê¸°ë°˜ ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ ê´€ë¦¬ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.scheduler: Optional[AsyncIOScheduler] = None
        self.is_running = False
        self.config = WorkerConfig.get_default_config()  # ê¸°ë³¸ ì„¤ì •ê°’ ì‚¬ìš©
        self.job_history: List[Dict] = []
        self.max_history_size = 100
        self._config_loaded = False
        
    async def load_config_from_db(self):
        """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì›Œì»¤ ì„¤ì • ë¡œë“œ"""
        try:
            db = next(get_db())
            try:
                worker_config = WorkerConfig.load_or_create_config(db)
                self.config = worker_config.to_dict()
                self._config_loaded = True
                logger.info(f"Loaded worker config from database: {self.config}")
            finally:
                db.close()
        except Exception as e:
            logger.error(f"Failed to load config from database: {e}")
            # ê¸°ë³¸ê°’ ì‚¬ìš©
            self.config = WorkerConfig.get_default_config()
            logger.info("Using default worker configuration")
        
    async def save_config_to_db(self):
        """í˜„ì¬ ì„¤ì •ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        try:
            db = next(get_db())
            try:
                worker_config = WorkerConfig.load_or_create_config(db)
                worker_config.update_from_dict(self.config)
                db.commit()
                logger.info(f"Saved worker config to database: {self.config}")
            finally:
                db.close()
        except Exception as e:
            logger.error(f"Failed to save config to database: {e}")
        
    async def initialize(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™”"""
        if self.scheduler is not None:
            logger.warning("Scheduler already initialized")
            return
            
        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì„¤ì • ë¡œë“œ
        if not self._config_loaded:
            await self.load_config_from_db()
            
        # Job stores, executors, and job defaults (APScheduler 3.x)
        jobstores = {
            'default': MemoryJobStore()
        }
        
        executors = {
            'default': AsyncIOExecutor()  # max_workers ë§¤ê°œë³€ìˆ˜ ì œê±°
        }
        
        job_defaults = {
            'coalesce': self.config['coalesce'],
            'max_instances': self.config['max_instances']
        }
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ìƒì„±
        self.scheduler = AsyncIOScheduler(
            jobstores=jobstores,
            executors=executors,
            job_defaults=job_defaults,
            timezone='Asia/Seoul'
        )
        
        # ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ë“±ë¡ (APScheduler 3.x ë°©ì‹)
        self.scheduler.add_listener(self._job_executed, mask=events.EVENT_JOB_EXECUTED)
        self.scheduler.add_listener(self._job_error, mask=events.EVENT_JOB_ERROR)
        
        logger.info("Scheduler service initialized")
        
    async def start(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"""
        if not self.scheduler:
            await self.initialize()
            
        if self.is_running:
            logger.warning("Scheduler already running")
            return
            
        # ì„œë²„ ìƒíƒœ ì²´í¬ ì‘ì—… ìŠ¤ì¼€ì¤„ë§ (APScheduler 3.x ë°©ì‹)
        self.scheduler.add_job(
            self._check_all_servers_status,
            trigger=IntervalTrigger(seconds=self.config['server_check_interval']),
            id='server_status_check',
            name='ì„œë²„ ìƒíƒœ ìë™ ì²´í¬',
            replace_existing=True
        )
        
        self.scheduler.start()
        self.is_running = True
        
        logger.info(f"Scheduler started with {self.config['server_check_interval']}s interval")
        
    async def stop(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì •ì§€"""
        if not self.scheduler or not self.is_running:
            logger.warning("Scheduler not running")
            return
            
        self.scheduler.shutdown(wait=False)
        self.is_running = False
        
        logger.info("Scheduler stopped")
        
    async def restart(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì¬ì‹œì‘"""
        await self.stop()
        await self.start()
        
    def update_config(self, new_config: Dict):
        """ì„¤ì • ì—…ë°ì´íŠ¸"""
        old_interval = self.config['server_check_interval']
        self.config.update(new_config)
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì„¤ì • ì €ì¥
        import asyncio
        asyncio.create_task(self.save_config_to_db())
        
        # ê°„ê²©ì´ ë³€ê²½ë˜ë©´ ìŠ¤ì¼€ì¤„ëŸ¬ ì¬ì‹œì‘
        if self.is_running and old_interval != self.config['server_check_interval']:
            logger.info(f"Interval changed from {old_interval}s to {self.config['server_check_interval']}s")
            # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì¬ì‹œì‘ (ë¸”ë¡œí‚¹ ë°©ì§€)
            asyncio.create_task(self.restart())
            
    def get_status(self) -> Dict:
        """ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ ì¡°íšŒ"""
        if not self.scheduler:
            return {
                'running': False,
                'jobs': [],
                'config': self.config,
                'last_execution': None,
                'job_history_count': len(self.job_history)
            }
            
        jobs = []
        if self.scheduler.get_jobs():
            for job in self.scheduler.get_jobs():
                jobs.append({
                    'id': job.id,
                    'name': job.name,
                    'next_run': job.next_run_time.isoformat() if job.next_run_time else None,
                    'trigger': str(job.trigger)
                })
                
        last_execution = None
        if self.job_history:
            last_execution = self.job_history[-1].get('timestamp')
            
        return {
            'running': self.is_running,
            'jobs': jobs,
            'config': self.config,
            'last_execution': last_execution,
            'job_history_count': len(self.job_history)
        }
        
    def get_job_history(self, limit: int = 50) -> List[Dict]:
        """ì‘ì—… ì‹¤í–‰ ì´ë ¥ ì¡°íšŒ"""
        return self.job_history[-limit:] if limit else self.job_history
        
    async def _check_all_servers_status(self):
        """ëª¨ë“  í™œì„± ì„œë²„ì˜ ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ì—…ë°ì´íŠ¸"""
        start_time = datetime.now()
        logger.info("Starting scheduled server status check")
        
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ íšë“
            db = next(get_db())
            
            try:
                # ëª¨ë“  í™œì„±í™”ëœ ì„œë²„ ì¡°íšŒ
                servers = db.query(McpServer).filter(
                    McpServer.is_enabled == True
                ).all()
                
                checked_count = 0
                updated_count = 0
                error_count = 0
                tools_synced_count = 0
                
                for server in servers:
                    try:
                        # ì„œë²„ ìƒíƒœ í™•ì¸
                        server_config = {
                            'command': server.command,
                            'args': server.args or [],
                            'env': server.env or {},
                            'timeout': 30
                        }
                        
                        unique_server_id = f"{server.project_id}_{server.name}"
                        status = await mcp_connection_service.check_server_status(
                            unique_server_id, server_config
                        )
                        
                        # ğŸ”„ ê°œì„ ëœ ìƒíƒœ ì—…ë°ì´íŠ¸: ServerStatusService ì‚¬ìš©
                        if status == "online":
                            new_status = McpServerStatus.ACTIVE
                        elif status == "offline":
                            new_status = McpServerStatus.INACTIVE
                        else:
                            new_status = McpServerStatus.ERROR
                            
                        # ìƒíƒœê°€ ë³€ê²½ëœ ê²½ìš°ë§Œ ì—…ë°ì´íŠ¸
                        if server.status != new_status:
                            # ServerStatusServiceë¥¼ í†µí•œ í†µí•© ìƒíƒœ ì—…ë°ì´íŠ¸
                            success = await ServerStatusService.update_server_status_by_name(
                                server_name=server.name,
                                project_id=server.project_id,
                                status=new_status,
                                db=db,
                                connection_type="SCHEDULER_CHECK",
                                error_message=str(e) if new_status == McpServerStatus.ERROR else None
                            )
                            
                            if success:
                                updated_count += 1
                                logger.info(f"ğŸ“Š [SCHEDULER] Updated server {server.name} status: {server.status} â†’ {new_status.value}")
                            else:
                                logger.warning(f"âš ï¸ [SCHEDULER] Failed to update server {server.name} status via ServerStatusService")
                                # í´ë°±: ì§ì ‘ ì—…ë°ì´íŠ¸
                                server.status = new_status
                                server.last_used_at = datetime.utcnow()
                                updated_count += 1
                        
                        # ì˜¨ë¼ì¸ ì„œë²„ì˜ ë„êµ¬ ëª©ë¡ ë™ê¸°í™”
                        if new_status == McpServerStatus.ACTIVE:
                            try:
                                tools_updated = await self._sync_server_tools(server, db)
                                if tools_updated > 0:
                                    tools_synced_count += tools_updated
                                    logger.info(f"Synced {tools_updated} tools for server {server.name}")
                            except Exception as tool_sync_error:
                                logger.error(f"Failed to sync tools for server {server.name}: {tool_sync_error}")
                                # ë„êµ¬ ë™ê¸°í™” ì‹¤íŒ¨ëŠ” ì„œë²„ ìƒíƒœì— ì˜í–¥ì„ ì£¼ì§€ ì•ŠìŒ
                            
                        checked_count += 1
                        
                    except Exception as e:
                        error_count += 1
                        logger.error(f"Error checking server {server.name}: {e}")
                        
                        # ğŸ”„ ì—ëŸ¬ ìƒíƒœ ì—…ë°ì´íŠ¸: ServerStatusService ì‚¬ìš©
                        try:
                            await ServerStatusService.update_server_status_by_name(
                                server_name=server.name,
                                project_id=server.project_id,
                                status=McpServerStatus.ERROR,
                                db=db,
                                connection_type="SCHEDULER_ERROR",
                                error_message=str(e)
                            )
                        except Exception as update_error:
                            logger.error(f"âŒ Failed to update error status via ServerStatusService: {update_error}")
                            # í´ë°±: ì§ì ‘ ì—…ë°ì´íŠ¸
                            server.status = McpServerStatus.ERROR
                            server.last_error = str(e)
                            server.last_used_at = datetime.utcnow()
                        
                # ë³€ê²½ì‚¬í•­ ì»¤ë°‹
                db.commit()
                
                execution_time = (datetime.now() - start_time).total_seconds()
                
                # ì‹¤í–‰ ì´ë ¥ ì €ì¥
                self._add_job_history({
                    'timestamp': start_time.isoformat(),
                    'duration': execution_time,
                    'checked_count': checked_count,
                    'updated_count': updated_count,
                    'error_count': error_count,
                    'tools_synced_count': tools_synced_count,
                    'status': 'success'
                })
                
                logger.info(
                    f"Scheduled server check completed: "
                    f"checked={checked_count}, updated={updated_count}, "
                    f"tools_synced={tools_synced_count}, errors={error_count}, "
                    f"duration={execution_time:.2f}s"
                )
                
            finally:
                db.close()
                
        except Exception as e:
            execution_time = (datetime.now() - start_time).total_seconds()
            logger.error(f"Scheduled server check failed: {e}")
            
            # ì‹¤í–‰ ì´ë ¥ ì €ì¥ (ì‹¤íŒ¨)
            self._add_job_history({
                'timestamp': start_time.isoformat(),
                'duration': execution_time,
                'error': str(e),
                'status': 'error'
            })
            
    def _job_executed(self, event):
        """ì‘ì—… ì‹¤í–‰ ì™„ë£Œ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬"""
        logger.debug(f"Job {event.job_id} executed successfully")
        
    def _job_error(self, event):
        """ì‘ì—… ì‹¤í–‰ ì˜¤ë¥˜ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬"""
        logger.error(f"Job {event.job_id} failed: {event.exception}")
        
    async def _sync_server_tools(self, server: McpServer, db: Session) -> int:
        """ì„œë²„ì˜ ë„êµ¬ ëª©ë¡ì„ ë™ê¸°í™”í•˜ê³  ì—…ë°ì´íŠ¸ëœ ë„êµ¬ ê°œìˆ˜ ë°˜í™˜"""
        try:
            # ì„œë²„ ì„¤ì • ì¤€ë¹„
            server_config = {
                'command': server.command,
                'args': server.args or [],
                'env': server.env or {},
                'timeout': 30
            }
            
            unique_server_id = f"{server.project_id}_{server.name}"
            
            # ì‹¤ì œ ì„œë²„ì—ì„œ ë„êµ¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            current_tools = await mcp_connection_service.get_server_tools(
                unique_server_id, server_config
            )
            
            # í˜„ì¬ DBì— ì €ì¥ëœ ë„êµ¬ ëª©ë¡
            existing_tools = {tool.name: tool for tool in server.tools}
            current_tool_names = {tool.get('name') for tool in current_tools if tool.get('name')}
            
            tools_updated = 0
            
            # ìƒˆë¡œìš´ ë„êµ¬ ì¶”ê°€ ë˜ëŠ” ê¸°ì¡´ ë„êµ¬ ì—…ë°ì´íŠ¸
            for tool_data in current_tools:
                tool_name = tool_data.get('name')
                if not tool_name:
                    continue
                    
                if tool_name in existing_tools:
                    # ê¸°ì¡´ ë„êµ¬ ì—…ë°ì´íŠ¸
                    existing_tool = existing_tools[tool_name]
                    existing_tool.description = tool_data.get('description', '')
                    existing_tool.input_schema = tool_data.get('inputSchema', {})
                    existing_tool.last_seen_at = datetime.utcnow()
                else:
                    # ìƒˆë¡œìš´ ë„êµ¬ ì¶”ê°€
                    new_tool = McpTool(
                        server_id=server.id,
                        name=tool_name,
                        display_name=tool_data.get('displayName') or tool_name,
                        description=tool_data.get('description', ''),
                        input_schema=tool_data.get('inputSchema', {}),
                        discovered_at=datetime.utcnow(),
                        last_seen_at=datetime.utcnow()
                    )
                    db.add(new_tool)
                    tools_updated += 1
                    
            # ë” ì´ìƒ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë„êµ¬ ì œê±°
            for tool_name, tool in existing_tools.items():
                if tool_name not in current_tool_names:
                    db.delete(tool)
                    tools_updated += 1
                    
            return tools_updated
            
        except Exception as e:
            logger.error(f"Error syncing tools for server {server.name}: {e}")
            return 0

    def _add_job_history(self, entry: Dict):
        """ì‘ì—… ì‹¤í–‰ ì´ë ¥ ì¶”ê°€"""
        self.job_history.append(entry)
        
        # ìµœëŒ€ ì´ë ¥ ìˆ˜ ì œí•œ
        if len(self.job_history) > self.max_history_size:
            self.job_history = self.job_history[-self.max_history_size:]


# ì „ì—­ ìŠ¤ì¼€ì¤„ëŸ¬ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
scheduler_service = SchedulerService()